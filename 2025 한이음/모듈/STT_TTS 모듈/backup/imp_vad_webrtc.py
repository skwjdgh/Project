import asyncio
import collections
from typing import Dict, Any, Optional

import numpy as np
import sounddevice as sd
import webrtcvad
from loguru import logger

from .def_interface import IVAD
from .def_exceptions import VADStreamError

class VoiceActivityDetector(IVAD):
    def __init__(self, config: Dict[str, Any], device_index: Optional[int] = None) -> None:
        self.device_index = device_index
        # WebRTC VADëŠ” 8000, 16000, 32000, 48000Hzë§Œ ì§€ì›í•©ë‹ˆë‹¤.
        self.HARDWARE_RATE = config.get('hardware_rate', 32000)
        # WebRTC VADëŠ” 10, 20, 30ms ê¸¸ì´ì˜ í”„ë ˆì„ë§Œ ì§€ì›í•©ë‹ˆë‹¤.
        self.frame_duration_ms = config.get('frame_duration_ms', 30)
        self.CHUNK_SAMPLES = int(self.HARDWARE_RATE * self.frame_duration_ms / 1000)
        
        # VAD ë¯¼ê°ë„ ì„¤ì • (0=ëŠìŠ¨í•¨, 3=ê°€ì¥ ë¯¼ê°í•¨)
        aggressiveness = config.get('aggressiveness', 3)
        self.vad = webrtcvad.Vad(aggressiveness)

        # ìŒì„± ì•/ë’¤ì— ì¶”ê°€í•  ì—¬ë°±(padding) ì„¤ì •
        self.padding_duration_ms = config.get('padding_duration_ms', 300)
        num_padding_frames = self.padding_duration_ms // self.frame_duration_ms
        
        self.min_silence_duration_ms = config.get('min_silence_duration_ms', 1000)
        
        # íŒ¨ë”©ì„ ìœ„í•œ ë§ ë²„í¼(ring buffer)
        self.ring_buffer = collections.deque(maxlen=num_padding_frames)
        self.is_listening = False

    async def listen(self) -> Optional[bytes]:
        if self.is_listening:
            return None
        self.is_listening = True
        
        loop = asyncio.get_running_loop()
        audio_queue = asyncio.Queue()
        
        def audio_callback(indata, frames, time, status):
            if status: logger.warning(status)
            loop.call_soon_threadsafe(audio_queue.put_nowait, bytes(indata))

        triggered = False
        speech_buffer = []
        
        num_silence_frames = 0
        min_silence_frames = self.min_silence_duration_ms // self.frame_duration_ms

        logger.info("ğŸ¤ ìŒì„± ì…ë ¥ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤...")
        stream = sd.InputStream(
            samplerate=self.HARDWARE_RATE, channels=1, dtype='int16', 
            blocksize=self.CHUNK_SAMPLES, device=self.device_index, 
            callback=audio_callback
        )
        with stream:
            try:
                while True:
                    frame = await audio_queue.get()
                    if len(frame) < (2 * self.CHUNK_SAMPLES):
                        continue

                    is_speech = self.vad.is_speech(frame, self.HARDWARE_RATE)
                    
                    if not triggered:
                        self.ring_buffer.append(frame)
                        if is_speech:
                            triggered = True
                            # ë²„í¼ì— ìˆë˜ íŒ¨ë”©ìš© ì˜¤ë””ì˜¤ë¥¼ ì‹¤ì œ ìŒì„± ë²„í¼ì— ì¶”ê°€
                            speech_buffer.extend(list(self.ring_buffer))
                            self.ring_buffer.clear()
                            num_silence_frames = 0
                    else:
                        speech_buffer.append(frame)
                        if not is_speech:
                            num_silence_frames += 1
                            if num_silence_frames > min_silence_frames:
                                return b''.join(speech_buffer)
                        else:
                            num_silence_frames = 0
            
            except asyncio.CancelledError:
                 logger.info("ë¦¬ìŠ¤ë‹ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                logger.error(f"ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë‚´ë¶€ì—ì„œ ì‹¤ì œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
                raise VADStreamError("ë§ˆì´í¬ ì…ë ¥ ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.") from e
            finally:
                self.is_listening = False
        return None

    def initialize(self) -> None: pass
    def is_initialized(self) -> bool: return True
    def close(self) -> None: logger.info("VAD ëª¨ë“ˆì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")